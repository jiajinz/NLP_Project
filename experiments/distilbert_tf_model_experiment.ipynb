{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707ea0e2-ece3-43a5-8cee-ae3c2fb491f4",
   "metadata": {},
   "source": [
    "# Experiment: Train Tensorflow DistilBERT Model Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7006621-50bd-4e71-ab7d-46fe72a4597f",
   "metadata": {},
   "source": [
    "## Confirm Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334b7bda-1ffe-467b-b90c-16752289eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : northeastern\n",
      "    active env location : /home/curtis/anaconda3/envs/northeastern\n",
      "            shell level : 2\n",
      "       user config file : /home/curtis/.condarc\n",
      " populated config files : /home/curtis/anaconda3/.condarc\n",
      "          conda version : 24.9.2\n",
      "    conda-build version : 24.9.0\n",
      "         python version : 3.12.7.final.0\n",
      "                 solver : libmamba (default)\n",
      "       virtual packages : __archspec=1=skylake\n",
      "                          __conda=24.9.2=0\n",
      "                          __glibc=2.39=0\n",
      "                          __linux=6.6.87.2=0\n",
      "                          __unix=0=0\n",
      "       base environment : /home/curtis/anaconda3  (writable)\n",
      "      conda av data dir : /home/curtis/anaconda3/etc/conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "          package cache : /home/curtis/anaconda3/pkgs\n",
      "                          /home/curtis/.conda/pkgs\n",
      "       envs directories : /home/curtis/anaconda3/envs\n",
      "                          /home/curtis/.conda/envs\n",
      "               platform : linux-64\n",
      "             user-agent : conda/24.9.2 requests/2.32.3 CPython/3.12.7 Linux/6.6.87.2-microsoft-standard-WSL2 ubuntu/24.04.1 glibc/2.39 solver/libmamba conda-libmamba-solver/24.9.0 libmambapy/1.5.8 aau/0.4.4 c/. s/. e/.\n",
      "                UID:GID : 1000:1000\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741bd87c-ad14-4814-b3f1-ce3cbb905ce8",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b7ad86-254e-44c2-b68a-9feeab1af1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 20:20:19.101620: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-02 20:20:19.617724: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751502019.783981    2944 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751502019.836404    2944 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751502020.223501    2944 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751502020.223581    2944 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751502020.223585    2944 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751502020.223587    2944 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-02 20:20:20.267196: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package wordnet to /home/curtis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/curtis/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from emolex.preprocessing import load_mental_health_sentiment_dataset, clean_text, encode_sentiment_labels, split_data, dl_text_vectorization\n",
    "from emolex.train import train_distilbert_model\n",
    "from emolex.evaluation import plot_training_history, generate_confusion_matrix, generate_classification_report\n",
    "from emolex.utils import detect_and_set_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced5de7-e66a-450a-bc22-ae77d08f872e",
   "metadata": {},
   "source": [
    "## Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d992bf9-63ad-4e96-8c28-9dc342e1429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU devices found despite TensorFlow being built with CUDA. Using CPU.\n",
      "TensorFlow is configured to use: CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 20:20:36.977743: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Detect and set up GPU or use CPU\n",
    "device_used = detect_and_set_device()\n",
    "print(f\"TensorFlow is configured to use: {device_used}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f81300-c1c4-4a4d-a6e3-58f1dd5a8a95",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9c38cc6-1003-4040-8cdd-34a131691e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51093 entries, 0 to 51092\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    51093 non-null  object\n",
      " 1   label   51093 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 798.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0                                         oh my gosh  Anxiety\n",
       "1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4  I'm restless and restless, it's been a month n...  Anxiety"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_mental_health_sentiment_dataset()\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee75bc-0560-4765-8c98-69e53bb210ac",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37bbc0d-e422-4ca3-8360-bbfee7612a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Text ---\n",
      "Text cleaning complete. Sample cleaned text:\n",
      "\n",
      "                                                     text  \\\n",
      "2466   My simple wish list about BTOB who haven't cro...   \n",
      "26843  It ruins my day when i wake up lol Each mornin...   \n",
      "20699  everyone is fakeeveryone acts like they care t...   \n",
      "43983  denpasar good luck look forward to the update ...   \n",
      "41011  i m not here to debate y all if my take make y...   \n",
      "\n",
      "                                              clean_text  \n",
      "2466   simple wish list btob havent crossed yet met s...  \n",
      "26843      ruin day wake lol morning wake dissapointment  \n",
      "20699  everyone fakeeveryone act like care boom backs...  \n",
      "43983  denpasar good luck look forward update run opt...  \n",
      "41011  debate take make uncomfortable good critical t...  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Cleaning Text ---\")\n",
    "df['clean_text'] = df[\"text\"].apply(clean_text)\n",
    "print(\"Text cleaning complete. Sample cleaned text:\")\n",
    "print(\"\\n\", df[[\"text\", \"clean_text\"]].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dda799-e583-417c-9670-ab72c20fa083",
   "metadata": {},
   "source": [
    "## Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c7351c-4862-4401-8048-d1b659fb2078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Encoding Labels ---\n",
      "Label Encoding Map: {'Anxiety': 0, 'Bipolar': 1, 'Depression': 2, 'Normal': 3, 'Personality disorder': 4, 'Stress': 5, 'Suicidal': 6}\n",
      "Label encoding complete. Sample encoded labels:\n",
      "\n",
      "           label  label_encoded\n",
      "4503     Normal              3\n",
      "47918    Stress              5\n",
      "44687    Normal              3\n",
      "7686   Suicidal              6\n",
      "29958    Normal              3\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Encoding Labels ---\")\n",
    "df, encoder = encode_sentiment_labels(df)\n",
    "print(\"Label encoding complete. Sample encoded labels:\")\n",
    "print(\"\\n\", df[['label', 'label_encoded']].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782c76f-4c69-49d9-bc97-7b8195df974c",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c70d1162-6e0b-47fd-b62c-c1997e0362e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Perform Train-Test Split ---\n",
      "Train set size: 40874 samples\n",
      "Test set size: 10219 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Perform Train-Test Split ---\")\n",
    "X_train_raw, X_test_raw, y_train, y_test = split_data(df) \n",
    "print(f\"Train set size: {len(X_train_raw)} samples\")\n",
    "print(f\"Test set size: {len(X_test_raw)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddf0f4-35f6-4a3c-936c-f53d79a8627b",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030b483-993f-42a0-a6da-6174adc3b5bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DistilBERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/curtis/anaconda3/envs/northeastern/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Hugging Face Datasets from input data...\n",
      "Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb05dedec8442188564f608ebde81b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40874 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d0d5a889bf43248d2d7e030390b023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensuring labels are native integers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a863e83a8da423bb32b40a36a22031a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40874 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f39bceddcf744e4ac9295cfe632bb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting dataset format to TensorFlow...\n",
      "Creating data collator...\n",
      "Converting Hugging Face Datasets to TensorFlow Datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/curtis/anaconda3/envs/northeastern/lib/python3.10/site-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TFDistilBertForSequenceClassification model with 7 labels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Starting DistilBERT model training for 3 epochs...\n",
      "Epoch 1/3\n",
      "  2/639 [..............................] - ETA: 2:12:46 - loss: 1.8133 - accuracy: 0.1797"
     ]
    }
   ],
   "source": [
    "model, history = train_distilbert_model(X_train_raw, y_train, X_test_raw, y_test, len(encoder.classes_), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941043d-f31a-4a24-8882-d2a9a9e176bb",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac7579-6581-4b09-aea6-741efcfd4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Plot Training History ---\")\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e442c4b-0b7e-4106-916b-12f7511b7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Predict Test Classes ---\")\n",
    "y_pred = model.predict(X_test_pad_filtered)\n",
    "y_pred_classes = y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70b794-040a-4b88-8b47-b13e8f36c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Generate Confusion Matrix ---\")\n",
    "fig, ax = generate_confusion_matrix(y_test_filtered, y_pred_classes, class_labels=encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe04ed-e12f-498e-ba74-e7a8c250fd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Generate Classification Report ---\")\n",
    "generate_classification_report(y_test_filtered, y_pred_classes, class_labels=encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df75c2-15e1-4d43-96af-af61d00ec7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tensorflow-gpu-neiderer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
