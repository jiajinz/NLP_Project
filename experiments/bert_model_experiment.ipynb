{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707ea0e2-ece3-43a5-8cee-ae3c2fb491f4",
   "metadata": {},
   "source": [
    "# Experiment: Train/Tune BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7006621-50bd-4e71-ab7d-46fe72a4597f",
   "metadata": {},
   "source": [
    "## Confirm Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334b7bda-1ffe-467b-b90c-16752289eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : northeastern\n",
      "    active env location : /home/curtis/anaconda3/envs/northeastern\n",
      "            shell level : 2\n",
      "       user config file : /home/curtis/.condarc\n",
      " populated config files : /home/curtis/anaconda3/.condarc\n",
      "          conda version : 24.9.2\n",
      "    conda-build version : 24.9.0\n",
      "         python version : 3.12.7.final.0\n",
      "                 solver : libmamba (default)\n",
      "       virtual packages : __archspec=1=skylake\n",
      "                          __conda=24.9.2=0\n",
      "                          __glibc=2.39=0\n",
      "                          __linux=6.6.87.2=0\n",
      "                          __unix=0=0\n",
      "       base environment : /home/curtis/anaconda3  (writable)\n",
      "      conda av data dir : /home/curtis/anaconda3/etc/conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "          package cache : /home/curtis/anaconda3/pkgs\n",
      "                          /home/curtis/.conda/pkgs\n",
      "       envs directories : /home/curtis/anaconda3/envs\n",
      "                          /home/curtis/.conda/envs\n",
      "               platform : linux-64\n",
      "             user-agent : conda/24.9.2 requests/2.32.3 CPython/3.12.7 Linux/6.6.87.2-microsoft-standard-WSL2 ubuntu/24.04.1 glibc/2.39 solver/libmamba conda-libmamba-solver/24.9.0 libmambapy/1.5.8 aau/0.4.4 c/. s/. e/.\n",
      "                UID:GID : 1000:1000\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741bd87c-ad14-4814-b3f1-ce3cbb905ce8",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b7ad86-254e-44c2-b68a-9feeab1af1b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 19:34:50.259982: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-02 19:34:50.271702: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751499290.284038    2437 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751499290.287777    2437 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751499290.297968    2437 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751499290.297997    2437 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751499290.297999    2437 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751499290.298000    2437 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-02 19:34:50.302115: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package wordnet to /home/curtis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/curtis/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from emolex.preprocessing import load_mental_health_sentiment_dataset, clean_text, encode_sentiment_labels, split_data, dl_text_vectorization\n",
    "from emolex.train import train_bert_model\n",
    "from emolex.evaluation import plot_training_history, generate_confusion_matrix, generate_classification_report\n",
    "from emolex.utils import detect_and_set_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced5de7-e66a-450a-bc22-ae77d08f872e",
   "metadata": {},
   "source": [
    "## Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d992bf9-63ad-4e96-8c28-9dc342e1429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU devices found despite TensorFlow being built with CUDA. Using CPU.\n",
      "TensorFlow is configured to use: CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 19:34:58.679486: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Detect and set up GPU or use CPU\n",
    "device_used = detect_and_set_device()\n",
    "print(f\"TensorFlow is configured to use: {device_used}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f81300-c1c4-4a4d-a6e3-58f1dd5a8a95",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9c38cc6-1003-4040-8cdd-34a131691e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51093 entries, 0 to 51092\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    51093 non-null  object\n",
      " 1   label   51093 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 798.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0                                         oh my gosh  Anxiety\n",
       "1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4  I'm restless and restless, it's been a month n...  Anxiety"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_mental_health_sentiment_dataset()\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee75bc-0560-4765-8c98-69e53bb210ac",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37bbc0d-e422-4ca3-8360-bbfee7612a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Text ---\n",
      "Text cleaning complete. Sample cleaned text:\n",
      "\n",
      "                                                     text  \\\n",
      "12667  I cannot stop thinking about killing myself ev...   \n",
      "28451  He came after me a few times so I got away and...   \n",
      "7350   Tried of consciousness , I do not want it Just...   \n",
      "16692  Right now everything is fine in my life but I ...   \n",
      "27491  I've been through treatment and had a period o...   \n",
      "\n",
      "                                              clean_text  \n",
      "12667  cannot stop thinking killing even good mood ch...  \n",
      "28451  came time got away called cop arrested restrai...  \n",
      "7350                  tried consciousness want want stop  \n",
      "16692  right everything fine life feeling urge finish...  \n",
      "27491  ive treatment period relative health stretch b...  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Cleaning Text ---\")\n",
    "df['clean_text'] = df[\"text\"].apply(clean_text)\n",
    "print(\"Text cleaning complete. Sample cleaned text:\")\n",
    "print(\"\\n\", df[[\"text\", \"clean_text\"]].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dda799-e583-417c-9670-ab72c20fa083",
   "metadata": {},
   "source": [
    "## Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c7351c-4862-4401-8048-d1b659fb2078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Encoding Labels ---\n",
      "Label Encoding Map: {'Anxiety': 0, 'Bipolar': 1, 'Depression': 2, 'Normal': 3, 'Personality disorder': 4, 'Stress': 5, 'Suicidal': 6}\n",
      "Label encoding complete. Sample encoded labels:\n",
      "\n",
      "             label  label_encoded\n",
      "43765      Normal              3\n",
      "1561       Normal              3\n",
      "5710       Normal              3\n",
      "2034       Normal              3\n",
      "14052  Depression              2\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Encoding Labels ---\")\n",
    "df, encoder = encode_sentiment_labels(df)\n",
    "print(\"Label encoding complete. Sample encoded labels:\")\n",
    "print(\"\\n\", df[['label', 'label_encoded']].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782c76f-4c69-49d9-bc97-7b8195df974c",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c70d1162-6e0b-47fd-b62c-c1997e0362e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Perform Train-Test Split ---\n",
      "Train set size: 40874 samples\n",
      "Test set size: 10219 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Perform Train-Test Split ---\")\n",
    "X_train_raw, X_test_raw, y_train, y_test = split_data(df) \n",
    "print(f\"Train set size: {len(X_train_raw)} samples\")\n",
    "print(f\"Test set size: {len(X_test_raw)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddf0f4-35f6-4a3c-936c-f53d79a8627b",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602dc4b8-c1bc-45ec-8ff0-6734637fff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/curtis/anaconda3/envs/northeastern/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Hugging Face Datasets from input data...\n",
      "Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfadf806c8046848729708832b75a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40874 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f300ac8b3a4a55ae8521e111ed61ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c8189bb6264a368b8bda6c78ec902f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40874 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e130362e153a48989bea468e7f63fb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained BERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining training arguments...\n",
      "Loading evaluation metrics...\n",
      "Setting up Hugging Face Trainer...\n",
      "Starting BERT model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/curtis/anaconda3/envs/northeastern/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='7665' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  14/7665 01:29 < 15:50:28, 0.13 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer, results = train_bert_model(X_train_raw, y_train, X_test_raw, y_test, len(encoder.classes_), num_train_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941043d-f31a-4a24-8882-d2a9a9e176bb",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac7579-6581-4b09-aea6-741efcfd4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Plot Training History ---\")\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e442c4b-0b7e-4106-916b-12f7511b7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Predict Test Classes ---\")\n",
    "y_pred = model.predict(X_test_pad_filtered)\n",
    "y_pred_classes = y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70b794-040a-4b88-8b47-b13e8f36c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Generate Confusion Matrix ---\")\n",
    "fig, ax = generate_confusion_matrix(y_test_filtered, y_pred_classes, class_labels=encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe04ed-e12f-498e-ba74-e7a8c250fd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Generate Classification Report ---\")\n",
    "generate_classification_report(y_test_filtered, y_pred_classes, class_labels=encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df75c2-15e1-4d43-96af-af61d00ec7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
