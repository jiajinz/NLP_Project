{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707ea0e2-ece3-43a5-8cee-ae3c2fb491f4",
   "metadata": {},
   "source": [
    "# Experiment: Train/Tune BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7006621-50bd-4e71-ab7d-46fe72a4597f",
   "metadata": {},
   "source": [
    "## Confirm Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334b7bda-1ffe-467b-b90c-16752289eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : northeastern\n",
      "    active env location : /home/curtis/anaconda3/envs/northeastern\n",
      "            shell level : 2\n",
      "       user config file : /home/curtis/.condarc\n",
      " populated config files : /home/curtis/anaconda3/.condarc\n",
      "          conda version : 24.9.2\n",
      "    conda-build version : 24.9.0\n",
      "         python version : 3.12.7.final.0\n",
      "                 solver : libmamba (default)\n",
      "       virtual packages : __archspec=1=skylake\n",
      "                          __conda=24.9.2=0\n",
      "                          __glibc=2.39=0\n",
      "                          __linux=6.6.87.2=0\n",
      "                          __unix=0=0\n",
      "       base environment : /home/curtis/anaconda3  (writable)\n",
      "      conda av data dir : /home/curtis/anaconda3/etc/conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "          package cache : /home/curtis/anaconda3/pkgs\n",
      "                          /home/curtis/.conda/pkgs\n",
      "       envs directories : /home/curtis/anaconda3/envs\n",
      "                          /home/curtis/.conda/envs\n",
      "               platform : linux-64\n",
      "             user-agent : conda/24.9.2 requests/2.32.3 CPython/3.12.7 Linux/6.6.87.2-microsoft-standard-WSL2 ubuntu/24.04.1 glibc/2.39 solver/libmamba conda-libmamba-solver/24.9.0 libmambapy/1.5.8 aau/0.4.4 c/. s/. e/.\n",
      "                UID:GID : 1000:1000\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741bd87c-ad14-4814-b3f1-ce3cbb905ce8",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b7ad86-254e-44c2-b68a-9feeab1af1b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 17:04:50.736391: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-02 17:04:50.753102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751490290.764785   51158 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751490290.767944   51158 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751490290.776221   51158 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751490290.776246   51158 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751490290.776247   51158 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751490290.776248   51158 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-02 17:04:50.779731: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package wordnet to /home/curtis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/curtis/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from emolex.preprocessing import load_mental_health_sentiment_dataset, clean_text, encode_sentiment_labels, split_data, dl_text_vectorization\n",
    "from emolex.train import train_bert_model\n",
    "from emolex.evaluation import plot_training_history, generate_confusion_matrix, generate_classification_report\n",
    "from emolex.utils import detect_and_set_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced5de7-e66a-450a-bc22-ae77d08f872e",
   "metadata": {},
   "source": [
    "## Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d992bf9-63ad-4e96-8c28-9dc342e1429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU devices found despite TensorFlow being built with CUDA. Using CPU.\n",
      "TensorFlow is configured to use: CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 17:04:55.686658: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Detect and set up GPU or use CPU\n",
    "device_used = detect_and_set_device()\n",
    "print(f\"TensorFlow is configured to use: {device_used}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f81300-c1c4-4a4d-a6e3-58f1dd5a8a95",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9c38cc6-1003-4040-8cdd-34a131691e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51093 entries, 0 to 51092\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    51093 non-null  object\n",
      " 1   label   51093 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 798.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0                                         oh my gosh  Anxiety\n",
       "1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4  I'm restless and restless, it's been a month n...  Anxiety"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_mental_health_sentiment_dataset()\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee75bc-0560-4765-8c98-69e53bb210ac",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37bbc0d-e422-4ca3-8360-bbfee7612a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Text ---\n",
      "Text cleaning complete. Sample cleaned text:\n",
      "\n",
      "                                                     text  \\\n",
      "13922  Wanted to kill myself the second I woke up. Ju...   \n",
      "43442                         working on my senior paper   \n",
      "26922  I am so tired of hurting and hurting myself ca...   \n",
      "40949  ethocide mina mina anca oc armenian turkish co...   \n",
      "21580  My head is so foggy. I stare into nothingness ...   \n",
      "\n",
      "                                              clean_text  \n",
      "13922      wanted kill second woke fantasy premeditation  \n",
      "43442                               working senior paper  \n",
      "26922  tired hurting hurting much bf might leave soon...  \n",
      "40949  ethocide mina mina anca oc armenian turkish co...  \n",
      "21580  head foggy stare nothingness cannot keep conve...  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Cleaning Text ---\")\n",
    "df['clean_text'] = df[\"text\"].apply(clean_text)\n",
    "print(\"Text cleaning complete. Sample cleaned text:\")\n",
    "print(\"\\n\", df[[\"text\", \"clean_text\"]].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dda799-e583-417c-9670-ab72c20fa083",
   "metadata": {},
   "source": [
    "## Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c7351c-4862-4401-8048-d1b659fb2078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Encoding Labels ---\n",
      "Label Encoding Map: {'Anxiety': 0, 'Bipolar': 1, 'Depression': 2, 'Normal': 3, 'Personality disorder': 4, 'Stress': 5, 'Suicidal': 6}\n",
      "Label encoding complete. Sample encoded labels:\n",
      "\n",
      "             label  label_encoded\n",
      "18469  Depression              2\n",
      "43672      Normal              3\n",
      "40366  Depression              2\n",
      "26360    Suicidal              6\n",
      "17156    Suicidal              6\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Encoding Labels ---\")\n",
    "df, encoder = encode_sentiment_labels(df)\n",
    "print(\"Label encoding complete. Sample encoded labels:\")\n",
    "print(\"\\n\", df[['label', 'label_encoded']].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782c76f-4c69-49d9-bc97-7b8195df974c",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c70d1162-6e0b-47fd-b62c-c1997e0362e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Perform Train-Test Split ---\n",
      "Train set size: 40874 samples\n",
      "Test set size: 10219 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Perform Train-Test Split ---\")\n",
    "X_train_raw, X_test_raw, y_train, y_test = split_data(df) \n",
    "print(f\"Train set size: {len(X_train_raw)} samples\")\n",
    "print(f\"Test set size: {len(X_test_raw)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddf0f4-35f6-4a3c-936c-f53d79a8627b",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602dc4b8-c1bc-45ec-8ff0-6734637fff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Creating Hugging Face Datasets from input data...\n",
      "Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24c2a4fa8e2413b8cbe2bcfdd5bbb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40874 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095fe1f7399f4ef59bbb11ac70d1a155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b5baa085d542e4ab407cbbbe17f711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40874 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7887469768fb4eb9b63ab4e759cbd8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained BERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining training arguments...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer, results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_bert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/grad_school/northeastern/ie7500/project/NLP_Project/src/emolex/train.py:156\u001b[0m, in \u001b[0;36mtrain_bert_model\u001b[0;34m(X_train, y_train, X_test, y_test, num_classes, max_len, output_dir, num_train_epochs, per_device_batch_size, logging_dir, random_seed)\u001b[0m\n\u001b[1;32m    153\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining training arguments...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_device_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_device_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Now consistent with docstring\u001b[39;49;00m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmacro_f1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Ensure this matches a key in compute_metrics\u001b[39;49;00m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading evaluation metrics...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    172\u001b[0m accuracy_metric \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "trainer, results = train_bert_model(X_train_raw, y_train, X_test_raw, y_test, len(encoder.classes_), num_train_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941043d-f31a-4a24-8882-d2a9a9e176bb",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac7579-6581-4b09-aea6-741efcfd4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Plot Training History ---\")\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e442c4b-0b7e-4106-916b-12f7511b7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Predict Test Classes ---\")\n",
    "y_pred = model.predict(X_test_pad_filtered)\n",
    "y_pred_classes = y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70b794-040a-4b88-8b47-b13e8f36c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Generate Confusion Matrix ---\")\n",
    "fig, ax = generate_confusion_matrix(y_test_filtered, y_pred_classes, class_labels=encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe04ed-e12f-498e-ba74-e7a8c250fd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Generate Classification Report ---\")\n",
    "generate_classification_report(y_test_filtered, y_pred_classes, class_labels=encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df75c2-15e1-4d43-96af-af61d00ec7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
