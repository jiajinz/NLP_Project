{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0805a30c-a9fd-48fd-92d8-8711576c1647",
   "metadata": {},
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ea8dc-5f38-4609-b4f5-79c1b8e3389d",
   "metadata": {
    "id": "da5ea8dc-5f38-4609-b4f5-79c1b8e3389d"
   },
   "source": [
    "## Data Processing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b69c46a-f7da-4423-a69d-9c36a5071934",
   "metadata": {
    "id": "0b69c46a-f7da-4423-a69d-9c36a5071934"
   },
   "outputs": [],
   "source": [
    "# Setup pandas display attributes\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3206630f-f299-4058-93af-c9b2de5cf35c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "3206630f-f299-4058-93af-c9b2de5cf35c",
    "outputId": "ab7d5ec5-99db-49ec-f6b3-f64dc630145f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 53043 entries, 0 to 53042\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    52681 non-null  object\n",
      " 1   label   53043 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless heart. All out of tune</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay in a restless and restless place</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'm still worried</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month now, boy. What do you mean?</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             text  \\\n",
       "0                                                                      oh my gosh   \n",
       "1                trouble sleeping, confused mind, restless heart. All out of tune   \n",
       "2  All wrong, back off dear, forward doubt. Stay in a restless and restless place   \n",
       "3                   I've shifted my focus to something else but I'm still worried   \n",
       "4        I'm restless and restless, it's been a month now, boy. What do you mean?   \n",
       "\n",
       "     label  \n",
       "0  Anxiety  \n",
       "1  Anxiety  \n",
       "2  Anxiety  \n",
       "3  Anxiety  \n",
       "4  Anxiety  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/mental_health_sentiment.csv', index_col=0)\n",
    "# Rename text and label columns to be generic\n",
    "df.rename(columns={\"statement\": \"text\", \"status\": \"label\"}, inplace=True)\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4bd0d78-eb19-4298-bd1c-c03c899265e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "a4bd0d78-eb19-4298-bd1c-c03c899265e8",
    "outputId": "1f65137b-c299-499a-947e-18d262a5753d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Normal                  16351\n",
       "Depression              15404\n",
       "Suicidal                10653\n",
       "Anxiety                  3888\n",
       "Bipolar                  2877\n",
       "Stress                   2669\n",
       "Personality disorder     1201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical features\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08da7d32-6400-4f34-a8bb-3aa6f3ed62b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08da7d32-6400-4f34-a8bb-3aa6f3ed62b7",
    "outputId": "f9268935-dae0-4e3f-f7da-e05372192056"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/neiderer.c/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/neiderer.c/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text processing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", '', text)              # remove punctuation and numbers\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb336da-8f83-4004-94d9-7a70e970b76c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcb336da-8f83-4004-94d9-7a70e970b76c",
    "outputId": "d519b0b0-0c5d-4ea7-f6d1-6e7f30978594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anxiety': np.int64(0), 'Bipolar': np.int64(1), 'Depression': np.int64(2), 'Normal': np.int64(3), 'Personality disorder': np.int64(4), 'Stress': np.int64(5), 'Suicidal': np.int64(6)}\n"
     ]
    }
   ],
   "source": [
    "# Encode Sentiment Labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['label_encoded'] = encoder.fit_transform(df['label'])\n",
    "\n",
    "# Print encoding map for reference\n",
    "label_map = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dbd9351-1bdd-4578-aca0-f943814f3a29",
   "metadata": {
    "id": "2dbd9351-1bdd-4578-aca0-f943814f3a29"
   },
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['clean_text']\n",
    "y = df['label_encoded']\n",
    "\n",
    "# 80-20 stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52884727-101b-4721-bda5-9dfaa8bfd042",
   "metadata": {
    "id": "52884727-101b-4721-bda5-9dfaa8bfd042"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 11:06:12.913493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751382372.934064 3360462 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751382372.940454 3360462 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751382372.957517 3360462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751382372.957535 3360462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751382372.957537 3360462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751382372.957539 3360462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-01 11:06:12.963210: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Text Vectorization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc4ab181-5bab-41b6-9581-35fcb2eaf710",
   "metadata": {
    "id": "dc4ab181-5bab-41b6-9581-35fcb2eaf710"
   },
   "outputs": [],
   "source": [
    "# Filter out empty sequences\n",
    "non_empty_train = X_train_pad.sum(axis=1) > 0\n",
    "X_train_pad = X_train_pad[non_empty_train]\n",
    "y_train = y_train[non_empty_train]\n",
    "\n",
    "non_empty_test = X_test_pad.sum(axis=1) > 0\n",
    "X_test_pad = X_test_pad[non_empty_test]\n",
    "y_test = y_test[non_empty_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcbc25-c750-4c20-a7ba-208b79515843",
   "metadata": {
    "id": "1edcbc25-c750-4c20-a7ba-208b79515843"
   },
   "source": [
    "## TF-IDF + Logistic Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ae2a2b-46c7-4086-8de1-402fa314c88d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "0064469f-9a6f-49dd-9fe3-503770da0f72",
    "outputId": "5e3ad0e3-2131-4a52-c65c-63f1a3ab972c"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10890b24-06c7-4b3c-9cc6-5e14ef6b19ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "0064469f-9a6f-49dd-9fe3-503770da0f72",
    "outputId": "5e3ad0e3-2131-4a52-c65c-63f1a3ab972c"
   },
   "outputs": [],
   "source": [
    "non_empty_text = X_train.str.strip().astype(bool)\n",
    "X_train = X_train[non_empty_text]\n",
    "y_train = y_train[non_empty_text]\n",
    "\n",
    "non_empty_text_test = X_test.str.strip().astype(bool)\n",
    "X_test = X_test[non_empty_text_test]\n",
    "y_test = y_test[non_empty_text_test]\n",
    "\n",
    "# TF-IDF feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "# %timeit logreg_model.fit(X_train_tfidf, y_train)\n",
    "logreg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "logreg_preds = logreg_model.predict(X_test_tfidf)\n",
    "print(\"Logistic Regression Report:\")\n",
    "print(classification_report(y_test, logreg_preds))\n",
    "\n",
    "# Confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, logreg_preds), annot=True, xticklabels=encoder.classes_, yticklabels=encoder.classes_, fmt='d', cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/lr_confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832b621-0205-4bd3-8071-3d7d030f7a1b",
   "metadata": {
    "id": "f832b621-0205-4bd3-8071-3d7d030f7a1b"
   },
   "source": [
    "## TF-IDF + SVM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7476fd-d264-4e12-b612-f3e510838d29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "id": "2b7476fd-d264-4e12-b612-f3e510838d29",
    "outputId": "e8f0a3d8-b29b-4f5b-a01b-73de647c3d88"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train SVM using the same TF-IDF features\n",
    "svm_model = LinearSVC()\n",
    "# %timeit svm_model.fit(X_train_tfidf, y_train)\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "svm_preds = svm_model.predict(X_test_tfidf)\n",
    "print(\"SVM Report:\")\n",
    "print(classification_report(y_test, svm_preds))\n",
    "\n",
    "# Confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, svm_preds), annot=True, xticklabels=encoder.classes_, yticklabels=encoder.classes_, fmt='d', cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - SVM\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/svm_confusion_matrix.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce260ef-acb4-4254-9dba-9be51697ca85",
   "metadata": {
    "id": "8ce260ef-acb4-4254-9dba-9be51697ca85"
   },
   "source": [
    "## Transformer-Based (BERT fine-tuning) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b909d8-09c6-4d36-a627-93e0b2a21d79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "acf4e15aa5a94806842cffe27019977a",
      "5ba1179198cb4707995d42be9a938ebb",
      "19a64d8318a94325a75c60fbd71f2980",
      "ec6b85b3760c4befaa92debd66f007e1",
      "8a43fa6c30f34cc894d76bb87b4912d5",
      "24693bc020274a38afbe5a7b37190829",
      "68c57aa0678c42cbbb9ea51eb15a2755",
      "d5903e07583c4805b4f2992139ab0bf8",
      "cfc0def516f5403e852e6a5d0ffa5013",
      "b23f049ccd5944959e3b24aee6084df4",
      "ef8bd20b068346b5bdadf093461ea7e8",
      "e2dca4c9eade4e479413f8772a6bbcae",
      "6aca1330f73e4d03b7b30d96a03c326c",
      "9e3f3b4a14d249ada13d9f87da5a0f00",
      "f178c84523e141c9a1aef43a766af762",
      "f5f93d8d3ec147989f975e2d4fe13228",
      "36c32ee2e024470d8f15c929c60ad256",
      "96288616b20743fcac0df3fd5bd5b216",
      "24f00d0991544965bbb873bdd198c894",
      "7be38e9d26f34a47a549861cdc60d61c",
      "d39ce362b76e45dea3dcc99c10d3a706",
      "1262bc4ad22b438eac064f6dbb64e6cf"
     ]
    },
    "id": "56b909d8-09c6-4d36-a627-93e0b2a21d79",
    "outputId": "a2d783e1-e37e-4509-a87d-028b912eb615"
   },
   "outputs": [],
   "source": [
    "# !pip install -U numpy datasets\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "\n",
    "# Convert train/test to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame({'text': X_train.tolist(), 'label': y_train.tolist()}))\n",
    "test_dataset = Dataset.from_pandas(pd.DataFrame({'text': X_test.tolist(), 'label': y_test.tolist()}))\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# Load BERT model\n",
    "num_labels = len(set(y_train))\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_output\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
    "    }\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "results = trainer.evaluate()\n",
    "print(\"BERT Evaluation:\", results)\n",
    "\n",
    "# Confusion matrix\n",
    "bert_preds = np.argmax(trainer.predict(test_dataset).predictions, axis=1)\n",
    "sns.heatmap(confusion_matrix(y_test, bert_preds), annot=True, fmt='d', cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - BERT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8JRkKhwPcjHU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JRkKhwPcjHU",
    "outputId": "59caa8f8-c0ec-4252-bfcb-9283d5caa23f"
   },
   "outputs": [],
   "source": [
    "print(\"BERT Classification Report:\\n\")\n",
    "print(classification_report(y_test, bert_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uxmrBA6ycjxT",
   "metadata": {
    "id": "uxmrBA6ycjxT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
